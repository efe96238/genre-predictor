{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d6b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60389729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b23c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres found: ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
      "Total tracks: 1000\n",
      "Example sample: ('data\\\\blues\\\\blues.00000.wav', 'blues')\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"data\"\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "genres = sorted([d for d in os.listdir(DATA_ROOT)\n",
    "                 if os.path.isdir(os.path.join(DATA_ROOT, d))])\n",
    "\n",
    "print(\"Genres found:\", genres)\n",
    "\n",
    "samples = []\n",
    "for genre in genres:\n",
    "  genre_dir = os.path.join(DATA_ROOT, genre)\n",
    "  for fname in os.listdir(genre_dir):\n",
    "    if fname.lower().endswith((\".wav\", \".mp3\")):\n",
    "      fpath = os.path.join(genre_dir, fname)\n",
    "      samples.append((fpath, genre))\n",
    "\n",
    "print(\"Total tracks:\", len(samples))\n",
    "print(\"Example sample:\", samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef90bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1000 After: 999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efefo\\AppData\\Local\\Temp\\ipykernel_24500\\2596890019.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=None, mono=True, duration=0.5)\n",
      "c:\\Users\\efefo\\Desktop\\programming\\python\\modules\\pytorch\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "def is_readable_audio(path):\n",
    "  try:\n",
    "    y, sr = librosa.load(path, sr=None, mono=True, duration=0.5)\n",
    "    return y is not None and len(y) > 0\n",
    "  except Exception:\n",
    "    return False\n",
    "\n",
    "good_samples = [(p, g) for (p, g) in samples if is_readable_audio(p)]\n",
    "print(\"Before:\", len(samples), \"After:\", len(good_samples))\n",
    "\n",
    "samples = good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58bb86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train tracks: 799\n",
      "Test tracks: 200\n",
      "\n",
      "Train per genre: Counter({'country': 80, 'rock': 80, 'hiphop': 80, 'pop': 80, 'reggae': 80, 'metal': 80, 'blues': 80, 'classical': 80, 'disco': 80, 'jazz': 79})\n",
      "Test per genre: Counter({'classical': 20, 'blues': 20, 'metal': 20, 'jazz': 20, 'country': 20, 'rock': 20, 'hiphop': 20, 'reggae': 20, 'disco': 20, 'pop': 20})\n"
     ]
    }
   ],
   "source": [
    "X = [s[0] for s in samples] #filepaths\n",
    "y = [s[1] for s in samples] #genres\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y) #stratify preserves proportions of the split\n",
    "\n",
    "print(f\"\\nTrain tracks: {len(X_train)}\")\n",
    "print(f\"Test tracks: {len(X_test)}\")\n",
    "\n",
    "print(f\"\\nTrain per genre: {Counter(y_train)}\")\n",
    "print(f\"Test per genre: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc8f4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label mapping: {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n"
     ]
    }
   ],
   "source": [
    "label_to_idx = {label: i for i, label in enumerate(genres)}\n",
    "idx_to_label = {i: label for label, i in label_to_idx.items()}\n",
    "\n",
    "print(f\"\\nLabel mapping: {label_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993bd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading audios\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "def load_audio(path):\n",
    "  y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
    "\n",
    "  #peak normalization\n",
    "  peak = np.max(np.abs(y))\n",
    "  if peak > 0:\n",
    "    y = y / peak\n",
    "\n",
    "  return y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca4a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation 10s clips\n",
    "\n",
    "CLIP_SECONDS = 10\n",
    "CLIP_SAMPLES = CLIP_SECONDS * SAMPLE_RATE\n",
    "\n",
    "def random_crop(y, clip_samples):\n",
    "  if len(y) < clip_samples:\n",
    "    return y\n",
    "  \n",
    "  max_start = len(y) - clip_samples\n",
    "  start = random.randint(0, max_start)\n",
    "  return y[start:start + clip_samples]\n",
    "\n",
    "#for testing\n",
    "def fixed_crop(y, clip_samples):\n",
    "  return y[:clip_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe83facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel spectogram\n",
    "\n",
    "N_FFT = 2048 #size of fft window\n",
    "HOP_LENGTH = 512 #step between fft windows\n",
    "N_MELS = 128 #number of mel freq bands\n",
    "\n",
    "def waveform_to_logmel(y, sr):\n",
    "  mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS, power=2.0)\n",
    "  log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "  return log_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee8d6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "  def __init__(self, filepaths, labels, label_to_idx, train=True):\n",
    "    self.filepaths = filepaths\n",
    "    self.labels = labels\n",
    "    self.label_to_idx = label_to_idx\n",
    "    self.train = train\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.filepaths)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    path = self.filepaths[idx]\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    #load audio\n",
    "    y, sr = load_audio(path)\n",
    "\n",
    "    #crop\n",
    "    if self.train:\n",
    "      y = random_crop(y, CLIP_SAMPLES)\n",
    "    else:\n",
    "      y = fixed_crop(y, CLIP_SAMPLES)\n",
    "\n",
    "    #waveform to logmel\n",
    "    log_mel = waveform_to_logmel(y, sr)\n",
    "    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-9) #normalization\n",
    "\n",
    "    #logmel to tensor\n",
    "    x = torch.tensor(log_mel, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    #label to index\n",
    "    y_label = self.label_to_idx[label]\n",
    "\n",
    "    return x, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95d237fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = GTZANDataset(X_train, y_train, label_to_idx, train=True)\n",
    "test_dataset = GTZANDataset(X_test, y_test, label_to_idx, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dadd7ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 128, 431]), torch.Size([16]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape check\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8bb4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenreClassifier(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GenreClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.block_1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(num_features=32),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(num_features=32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "      )\n",
    "    self.block_2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(num_features=64),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(num_features=64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "      )\n",
    "    self.block_3 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(num_features=128),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(num_features=128),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "      )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.AdaptiveAvgPool2d((1, 1)),\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(p=0.4),\n",
    "      nn.Linear(in_features=128, out_features=10)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.block_1(x)\n",
    "    x = self.block_2(x)\n",
    "    x = self.block_3(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = GenreClassifier().to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ac496df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d10384aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 1.8946 | Train Acc: 31.91% | Test Loss: 1.7610 | Test Acc: 34.50%\n",
      "Epoch 1 | Train Loss: 1.5580 | Train Acc: 44.93% | Test Loss: 1.4694 | Test Acc: 42.50%\n",
      "Epoch 2 | Train Loss: 1.4941 | Train Acc: 45.31% | Test Loss: 1.3715 | Test Acc: 47.50%\n",
      "Epoch 3 | Train Loss: 1.3706 | Train Acc: 51.19% | Test Loss: 1.7456 | Test Acc: 37.50%\n",
      "Epoch 4 | Train Loss: 1.3192 | Train Acc: 53.69% | Test Loss: 1.6654 | Test Acc: 40.50%\n",
      "Epoch 5 | Train Loss: 1.2537 | Train Acc: 58.82% | Test Loss: 1.1176 | Test Acc: 63.00%\n",
      "Epoch 6 | Train Loss: 1.2359 | Train Acc: 57.45% | Test Loss: 1.0086 | Test Acc: 71.50%\n",
      "Epoch 7 | Train Loss: 1.1076 | Train Acc: 60.70% | Test Loss: 1.1335 | Test Acc: 62.50%\n",
      "Epoch 8 | Train Loss: 1.1728 | Train Acc: 60.20% | Test Loss: 1.4169 | Test Acc: 45.00%\n",
      "Epoch 9 | Train Loss: 1.1150 | Train Acc: 59.32% | Test Loss: 1.3009 | Test Acc: 54.50%\n",
      "Epoch 10 | Train Loss: 1.0578 | Train Acc: 63.70% | Test Loss: 1.5904 | Test Acc: 45.50%\n",
      "Epoch 11 | Train Loss: 1.0923 | Train Acc: 61.33% | Test Loss: 1.0808 | Test Acc: 64.50%\n",
      "Epoch 12 | Train Loss: 1.0515 | Train Acc: 63.33% | Test Loss: 1.1135 | Test Acc: 61.00%\n",
      "Epoch 13 | Train Loss: 0.9915 | Train Acc: 64.71% | Test Loss: 1.1789 | Test Acc: 59.50%\n",
      "Epoch 14 | Train Loss: 0.9470 | Train Acc: 69.46% | Test Loss: 1.1811 | Test Acc: 62.00%\n",
      "Epoch 15 | Train Loss: 0.9890 | Train Acc: 67.96% | Test Loss: 0.9189 | Test Acc: 69.50%\n",
      "Epoch 16 | Train Loss: 0.8620 | Train Acc: 71.96% | Test Loss: 1.0112 | Test Acc: 61.50%\n",
      "Epoch 17 | Train Loss: 0.8734 | Train Acc: 70.46% | Test Loss: 0.9431 | Test Acc: 67.00%\n",
      "Epoch 18 | Train Loss: 0.8729 | Train Acc: 70.34% | Test Loss: 1.0354 | Test Acc: 64.50%\n",
      "Epoch 19 | Train Loss: 0.8253 | Train Acc: 71.84% | Test Loss: 0.8210 | Test Acc: 76.00%\n",
      "Epoch 20 | Train Loss: 0.7967 | Train Acc: 73.84% | Test Loss: 1.0631 | Test Acc: 66.50%\n",
      "Epoch 21 | Train Loss: 0.8507 | Train Acc: 73.09% | Test Loss: 1.4103 | Test Acc: 56.00%\n",
      "Epoch 22 | Train Loss: 0.8730 | Train Acc: 70.34% | Test Loss: 1.2484 | Test Acc: 57.00%\n",
      "Epoch 23 | Train Loss: 0.7449 | Train Acc: 75.97% | Test Loss: 0.8097 | Test Acc: 73.50%\n",
      "Epoch 24 | Train Loss: 0.7893 | Train Acc: 73.72% | Test Loss: 1.2508 | Test Acc: 61.50%\n",
      "Epoch 25 | Train Loss: 0.7631 | Train Acc: 75.22% | Test Loss: 1.1338 | Test Acc: 61.50%\n",
      "Epoch 26 | Train Loss: 0.7421 | Train Acc: 74.34% | Test Loss: 0.9904 | Test Acc: 73.00%\n",
      "Epoch 27 | Train Loss: 0.7331 | Train Acc: 75.97% | Test Loss: 0.9497 | Test Acc: 69.00%\n",
      "Epoch 28 | Train Loss: 0.6993 | Train Acc: 76.85% | Test Loss: 0.8371 | Test Acc: 71.50%\n",
      "Epoch 29 | Train Loss: 0.6883 | Train Acc: 75.97% | Test Loss: 1.2398 | Test Acc: 59.00%\n",
      "Epoch 30 | Train Loss: 0.6550 | Train Acc: 77.85% | Test Loss: 1.2169 | Test Acc: 62.50%\n",
      "Epoch 31 | Train Loss: 0.6694 | Train Acc: 77.47% | Test Loss: 0.7299 | Test Acc: 78.50%\n",
      "Epoch 32 | Train Loss: 0.6512 | Train Acc: 78.47% | Test Loss: 1.1439 | Test Acc: 61.50%\n",
      "Epoch 33 | Train Loss: 0.6411 | Train Acc: 79.60% | Test Loss: 1.1507 | Test Acc: 60.50%\n",
      "Epoch 34 | Train Loss: 0.6514 | Train Acc: 78.47% | Test Loss: 0.8049 | Test Acc: 75.50%\n",
      "Epoch 35 | Train Loss: 0.6115 | Train Acc: 79.97% | Test Loss: 0.7528 | Test Acc: 74.50%\n",
      "Epoch 36 | Train Loss: 0.6685 | Train Acc: 78.47% | Test Loss: 1.1390 | Test Acc: 60.00%\n",
      "Epoch 37 | Train Loss: 0.6496 | Train Acc: 78.10% | Test Loss: 1.7660 | Test Acc: 54.00%\n",
      "Epoch 38 | Train Loss: 0.6265 | Train Acc: 79.22% | Test Loss: 0.9671 | Test Acc: 70.00%\n",
      "Epoch 39 | Train Loss: 0.6167 | Train Acc: 79.85% | Test Loss: 0.9089 | Test Acc: 75.00%\n",
      "Epoch 40 | Train Loss: 0.6054 | Train Acc: 80.23% | Test Loss: 1.0976 | Test Acc: 66.00%\n",
      "Epoch 41 | Train Loss: 0.5698 | Train Acc: 81.85% | Test Loss: 0.7447 | Test Acc: 79.50%\n",
      "Epoch 42 | Train Loss: 0.5719 | Train Acc: 80.98% | Test Loss: 0.9499 | Test Acc: 69.50%\n",
      "Epoch 43 | Train Loss: 0.5180 | Train Acc: 83.48% | Test Loss: 0.7904 | Test Acc: 77.50%\n",
      "Epoch 44 | Train Loss: 0.5735 | Train Acc: 80.73% | Test Loss: 0.8185 | Test Acc: 75.00%\n",
      "Epoch 45 | Train Loss: 0.5410 | Train Acc: 83.60% | Test Loss: 1.0963 | Test Acc: 67.00%\n",
      "Epoch 46 | Train Loss: 0.5131 | Train Acc: 83.85% | Test Loss: 0.7832 | Test Acc: 79.00%\n",
      "Epoch 47 | Train Loss: 0.5744 | Train Acc: 81.10% | Test Loss: 0.7905 | Test Acc: 77.50%\n",
      "Epoch 48 | Train Loss: 0.5289 | Train Acc: 82.35% | Test Loss: 0.8333 | Test Acc: 78.50%\n",
      "Epoch 49 | Train Loss: 0.5339 | Train Acc: 83.35% | Test Loss: 0.8562 | Test Acc: 76.00%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 50\n",
    "best_test_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model_0.train()\n",
    "  epoch_loss = 0.0\n",
    "  epoch_correct = 0\n",
    "  epoch_total = 0\n",
    "\n",
    "  for X_batch, y_batch in train_loader:\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    y_logits = model_0(X_batch)\n",
    "    loss = loss_fn(y_logits, y_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * y_batch.size(0)\n",
    "    preds = torch.argmax(y_logits, dim=1)\n",
    "    epoch_correct += (preds == y_batch).sum().item()\n",
    "    epoch_total += y_batch.size(0)\n",
    "\n",
    "  train_loss = epoch_loss / epoch_total\n",
    "  train_acc = 100 * epoch_correct / epoch_total\n",
    "\n",
    "  model_0.eval()\n",
    "  test_loss = 0.0\n",
    "  test_correct = 0\n",
    "  test_total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "      X_batch = X_batch.to(device)\n",
    "      y_batch = y_batch.to(device)\n",
    "\n",
    "      y_logits = model_0(X_batch)\n",
    "      loss = loss_fn(y_logits, y_batch)\n",
    "\n",
    "      test_loss += loss.item() * y_batch.size(0)\n",
    "      preds = torch.argmax(y_logits, dim=1)\n",
    "      test_correct += (preds == y_batch).sum().item()\n",
    "      test_total += y_batch.size(0)\n",
    "\n",
    "  test_loss = test_loss / test_total\n",
    "  test_acc = 100 * test_correct / test_total\n",
    "\n",
    "  if test_acc > best_test_acc:\n",
    "    best_test_acc = test_acc\n",
    "    torch.save(model_0.state_dict(), \"models/best_model.pth\")\n",
    "\n",
    "  if epoch % 1 == 0:\n",
    "    print(\n",
    "      f\"Epoch {epoch} | \"\n",
    "      f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "      f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa7cce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model_0.state_dict(), \"models/firstrun.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d91aa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenreClassifier(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test inference\n",
    "\n",
    "model_1 = GenreClassifier()\n",
    "model_1.load_state_dict(torch.load(\"models/best_model.pth\"))\n",
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4589610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | true=classical  pred=classical  p(pred)= 99.67% p(true)= 99.67%\n",
      "1 | true=blues      pred=country    p(pred)= 28.56% p(true)= 20.60%\n",
      "2 | true=metal      pred=metal      p(pred)= 98.39% p(true)= 98.39%\n",
      "3 | true=jazz       pred=jazz       p(pred)= 95.29% p(true)= 95.29%\n",
      "4 | true=blues      pred=blues      p(pred)= 35.76% p(true)= 35.76%\n",
      "5 | true=country    pred=classical  p(pred)= 57.43% p(true)= 27.49%\n",
      "6 | true=rock       pred=rock       p(pred)= 53.92% p(true)= 53.92%\n",
      "7 | true=country    pred=country    p(pred)= 73.33% p(true)= 73.33%\n",
      "8 | true=hiphop     pred=disco      p(pred)= 77.38% p(true)=  0.41%\n",
      "9 | true=jazz       pred=jazz       p(pred)= 97.42% p(true)= 97.42%\n",
      "10 | true=blues      pred=blues      p(pred)= 72.26% p(true)= 72.26%\n",
      "11 | true=blues      pred=blues      p(pred)= 67.75% p(true)= 67.75%\n",
      "12 | true=reggae     pred=reggae     p(pred)= 86.80% p(true)= 86.80%\n",
      "13 | true=blues      pred=blues      p(pred)= 67.90% p(true)= 67.90%\n",
      "14 | true=rock       pred=rock       p(pred)= 57.80% p(true)= 57.80%\n",
      "15 | true=disco      pred=hiphop     p(pred)= 61.41% p(true)= 25.68%\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "  X_batch, y_batch = next(iter(test_loader))\n",
    "  X_batch = X_batch.to(device)\n",
    "\n",
    "  probs = torch.softmax(model_1(X_batch), dim=1)\n",
    "  preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "for i in range(16):\n",
    "  true_i = y_batch[i].item()\n",
    "  pred_i = preds[i].item()\n",
    "  p_pred = probs[i, pred_i].item() * 100\n",
    "  p_true = probs[i, true_i].item() * 100\n",
    "\n",
    "  print(\n",
    "    f\"{i} | true={idx_to_label[true_i]:10s} \"\n",
    "    f\"pred={idx_to_label[pred_i]:10s} \"\n",
    "    f\"p(pred)={p_pred:6.2f}% p(true)={p_true:6.2f}%\"\n",
    "  )\n",
    "\n",
    "#p(pred) is model's prediction of the class, p(true) is what it gave to the actual true class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2410145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now training with full dataset\n",
    "\n",
    "X_full = X_train + X_test\n",
    "y_full = y_train + y_test\n",
    "\n",
    "full_dataset = GTZANDataset(X_full, y_full, label_to_idx, train=True)\n",
    "full_loader = DataLoader(full_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f14f51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = GenreClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "855acda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 1.8060 | Train Acc: 37.14%\n",
      "Epoch 1 | Train Loss: 1.5214 | Train Acc: 47.65%\n",
      "Epoch 2 | Train Loss: 1.3880 | Train Acc: 51.85%\n",
      "Epoch 3 | Train Loss: 1.2779 | Train Acc: 55.06%\n",
      "Epoch 4 | Train Loss: 1.2113 | Train Acc: 60.56%\n",
      "Epoch 5 | Train Loss: 1.1526 | Train Acc: 61.36%\n",
      "Epoch 6 | Train Loss: 1.0858 | Train Acc: 62.56%\n",
      "Epoch 7 | Train Loss: 1.0402 | Train Acc: 64.16%\n",
      "Epoch 8 | Train Loss: 1.0294 | Train Acc: 64.36%\n",
      "Epoch 9 | Train Loss: 0.9762 | Train Acc: 68.37%\n",
      "Epoch 10 | Train Loss: 0.9666 | Train Acc: 67.37%\n",
      "Epoch 11 | Train Loss: 1.0014 | Train Acc: 65.47%\n",
      "Epoch 12 | Train Loss: 0.8719 | Train Acc: 72.97%\n",
      "Epoch 13 | Train Loss: 0.8605 | Train Acc: 71.37%\n",
      "Epoch 14 | Train Loss: 0.8526 | Train Acc: 72.07%\n",
      "Epoch 15 | Train Loss: 0.8880 | Train Acc: 70.27%\n",
      "Epoch 16 | Train Loss: 0.8521 | Train Acc: 72.17%\n",
      "Epoch 17 | Train Loss: 0.8145 | Train Acc: 72.57%\n",
      "Epoch 18 | Train Loss: 0.7816 | Train Acc: 73.27%\n",
      "Epoch 19 | Train Loss: 0.7807 | Train Acc: 75.08%\n",
      "Epoch 20 | Train Loss: 0.7311 | Train Acc: 76.98%\n",
      "Epoch 21 | Train Loss: 0.7556 | Train Acc: 74.27%\n",
      "Epoch 22 | Train Loss: 0.7335 | Train Acc: 75.78%\n",
      "Epoch 23 | Train Loss: 0.7543 | Train Acc: 74.77%\n",
      "Epoch 24 | Train Loss: 0.7118 | Train Acc: 75.68%\n",
      "Epoch 25 | Train Loss: 0.6742 | Train Acc: 77.58%\n",
      "Epoch 26 | Train Loss: 0.6776 | Train Acc: 76.78%\n",
      "Epoch 27 | Train Loss: 0.6858 | Train Acc: 76.88%\n",
      "Epoch 28 | Train Loss: 0.6811 | Train Acc: 77.48%\n",
      "Epoch 29 | Train Loss: 0.6525 | Train Acc: 77.38%\n",
      "Epoch 30 | Train Loss: 0.6507 | Train Acc: 78.28%\n",
      "Epoch 31 | Train Loss: 0.6249 | Train Acc: 79.48%\n",
      "Epoch 32 | Train Loss: 0.6361 | Train Acc: 79.48%\n",
      "Epoch 33 | Train Loss: 0.5926 | Train Acc: 80.88%\n",
      "Epoch 34 | Train Loss: 0.5841 | Train Acc: 80.68%\n",
      "Epoch 35 | Train Loss: 0.5857 | Train Acc: 79.98%\n",
      "Epoch 36 | Train Loss: 0.5632 | Train Acc: 81.08%\n",
      "Epoch 37 | Train Loss: 0.6326 | Train Acc: 79.68%\n",
      "Epoch 38 | Train Loss: 0.5803 | Train Acc: 81.78%\n",
      "Epoch 39 | Train Loss: 0.5939 | Train Acc: 80.48%\n",
      "Epoch 40 | Train Loss: 0.5475 | Train Acc: 81.58%\n",
      "Epoch 41 | Train Loss: 0.5477 | Train Acc: 81.78%\n",
      "Epoch 42 | Train Loss: 0.4951 | Train Acc: 82.78%\n",
      "Epoch 43 | Train Loss: 0.5609 | Train Acc: 82.18%\n",
      "Epoch 44 | Train Loss: 0.5128 | Train Acc: 82.08%\n",
      "Epoch 45 | Train Loss: 0.5057 | Train Acc: 84.08%\n",
      "Epoch 46 | Train Loss: 0.4704 | Train Acc: 84.68%\n",
      "Epoch 47 | Train Loss: 0.4535 | Train Acc: 84.58%\n",
      "Epoch 48 | Train Loss: 0.4924 | Train Acc: 82.98%\n",
      "Epoch 49 | Train Loss: 0.4588 | Train Acc: 85.89%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model_2.train()\n",
    "  epoch_loss = 0.0\n",
    "  epoch_correct = 0\n",
    "  epoch_total = 0\n",
    "\n",
    "  for X_batch, y_batch in full_loader:\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    y_logits = model_2(X_batch)\n",
    "    loss = loss_fn(y_logits, y_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item() * y_batch.size(0)\n",
    "    preds = torch.argmax(y_logits, dim=1)\n",
    "    epoch_correct += (preds == y_batch).sum().item()\n",
    "    epoch_total += y_batch.size(0)\n",
    "\n",
    "  train_loss = epoch_loss / epoch_total\n",
    "  train_acc = 100 * epoch_correct / epoch_total\n",
    "\n",
    "  if epoch % 1 == 0:\n",
    "    print(\n",
    "      f\"Epoch {epoch} | \"\n",
    "      f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2878c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model_2.state_dict(), \"models/final_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b48e2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenreClassifier(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = GenreClassifier()\n",
    "model_final.load_state_dict(torch.load(\"models/final_model.pth\"))\n",
    "model_final.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8a7bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_DIR = \"user_songs\"\n",
    "\n",
    "def predict_folder(model, folder):\n",
    "  model.eval()\n",
    "\n",
    "  files = []\n",
    "  for fname in os.listdir(folder):\n",
    "    if fname.lower().endswith((\".wav\", \".mp3\")):\n",
    "      files.append(os.path.join(folder, fname))\n",
    "\n",
    "  if len(files) == 0:\n",
    "    print(\"No .wav or .mp3 files found in:\", folder)\n",
    "    return\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for path in files:\n",
    "      y, sr = load_audio(path)\n",
    "      y = fixed_crop(y, CLIP_SAMPLES)\n",
    "\n",
    "      log_mel = waveform_to_logmel(y, sr)\n",
    "      log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-9)\n",
    "\n",
    "      x = torch.tensor(log_mel, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "      x = x.to(device)\n",
    "\n",
    "      logits = model(x)\n",
    "      probs = torch.softmax(logits, dim=1).squeeze(0)\n",
    "\n",
    "      pred_i = torch.argmax(probs).item()\n",
    "\n",
    "      print(\"\\nFile:\", os.path.basename(path))\n",
    "      print(\"Predicted:\", idx_to_label[pred_i])\n",
    "      for j, p in enumerate(probs):\n",
    "        print(f\"  {idx_to_label[j]}: {p.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c8af24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Bleed- Meshuggah (Full Version HD).mp3\n",
      "Predicted: metal\n",
      "  blues: 0.00%\n",
      "  classical: 0.00%\n",
      "  country: 0.00%\n",
      "  disco: 0.00%\n",
      "  hiphop: 0.34%\n",
      "  jazz: 0.00%\n",
      "  metal: 99.01%\n",
      "  pop: 0.23%\n",
      "  reggae: 0.00%\n",
      "  rock: 0.41%\n",
      "\n",
      "File: Holy Wars... The Punishment Due (2004 Remix).mp3\n",
      "Predicted: metal\n",
      "  blues: 0.00%\n",
      "  classical: 0.13%\n",
      "  country: 0.03%\n",
      "  disco: 0.09%\n",
      "  hiphop: 7.26%\n",
      "  jazz: 0.11%\n",
      "  metal: 69.57%\n",
      "  pop: 10.20%\n",
      "  reggae: 0.42%\n",
      "  rock: 12.19%\n",
      "\n",
      "File: Master of Puppets (Remastered).mp3\n",
      "Predicted: metal\n",
      "  blues: 0.05%\n",
      "  classical: 0.00%\n",
      "  country: 0.06%\n",
      "  disco: 1.65%\n",
      "  hiphop: 2.68%\n",
      "  jazz: 0.00%\n",
      "  metal: 78.12%\n",
      "  pop: 0.52%\n",
      "  reggae: 0.09%\n",
      "  rock: 16.83%\n"
     ]
    }
   ],
   "source": [
    "predict_folder(model_final, USER_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
